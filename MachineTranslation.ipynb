{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fc4db14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>अवधि को हाइलाइट रकें</td>\n",
       "      <td>Highlight duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...</td>\n",
       "      <td>The duration of the highlight box when selecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>सीमांत (बोर्डर) के रंग को हाइलाइट करें</td>\n",
       "      <td>Highlight border color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।</td>\n",
       "      <td>The color and opacity of the highlight border.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>भराई के रंग को हाइलाइट करें</td>\n",
       "      <td>Highlight fill color</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "5                               अवधि को हाइलाइट रकें   \n",
       "6  पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...   \n",
       "7             सीमांत (बोर्डर) के रंग को हाइलाइट करें   \n",
       "8      हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।    \n",
       "9                        भराई के रंग को हाइलाइट करें   \n",
       "\n",
       "                                             english  \n",
       "0     Give your application an accessibility workout  \n",
       "1                  Accerciser Accessibility Explorer  \n",
       "2     The default plugin layout for the bottom panel  \n",
       "3        The default plugin layout for the top panel  \n",
       "4     A list of plugins that are disabled by default  \n",
       "5                                 Highlight duration  \n",
       "6  The duration of the highlight box when selecti...  \n",
       "7                             Highlight border color  \n",
       "8     The color and opacity of the highlight border.  \n",
       "9                               Highlight fill color  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"D:\\hindi_english_parallel.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "45a9a5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561841, 2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bfe8344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape :  (30000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle (optional but recommended for randomness)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Take first 10,000 rows\n",
    "data = data.iloc[:30000]\n",
    "\n",
    "# Save it for training\n",
    "data.to_csv(\"subset_10k.csv\", index=False)\n",
    "print(\"data shape : \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b623bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_hindi(text):\n",
    "    # Handle non-string values (e.g., NaN, None, float)\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove characters that are not Hindi or spaces\n",
    "    text = re.sub(r\"[^\\u0900-\\u097F\\s]\", \"\", text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # Trim leading/trailing spaces\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "656a8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hindi\"] = data[\"hindi\"].apply(clean_hindi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f49988d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 बेशक तू तो बड़ा इज्ज़त वाला सरदार है\n",
       "1    आगामी विभिन्न आयोजनों प्रदर्शनियों तथा व्यापार...\n",
       "2                                                     \n",
       "3    तो यह सेकंड के हर घंटे के लिए छोटी इकाइयों सेक...\n",
       "4                                        किशनगढ़ अजमेर\n",
       "5                                            नामस्थानः\n",
       "6    मेरे पिताजी के वसीयत दार के बारे में मुझे पता ...\n",
       "7    समसामयिक साहित्य मनुष्य के अन्तर्मन और उसके वि...\n",
       "8    यह भी प्राख्यान किया गया है कि बौद्धिक संपदा अ...\n",
       "9    जैसा कि पीछे कहा जा चुका है उत्तराखंड में दो क...\n",
       "Name: hindi, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.hindi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b4311dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_english(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters (except spaces)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "485a3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"english\"] = data[\"english\"].apply(clean_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0cf9aa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         taste this you are a person mighty and noble\n",
       "1    click on the links below to know about various...\n",
       "2                       that s what the y intercept is\n",
       "3    the smaller units are seconds so it s 3600 sec...\n",
       "4                                           kishangarh\n",
       "5                                            namespace\n",
       "6               my father s legatee is not known to me\n",
       "7    contemporary literature probes deeper into the...\n",
       "8    it is also asserted that in another proceeding...\n",
       "9    this area as mentioned earlier consists of two...\n",
       "Name: english, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.english.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "666a61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a7963",
   "metadata": {},
   "source": [
    "Adding Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a09cf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['english'] = train_data['english'].apply(lambda x: '<sos> ' + x + ' <eos>')\n",
    "val_data['english'] = val_data['english'].apply(lambda x: '<sos> ' + x + ' <eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e8fe5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def yield_tokens(texts):\n",
    "    for sent in texts:\n",
    "        yield sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91509ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_vocab = build_vocab_from_iterator(yield_tokens(train_data['hindi']), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
    "english_vocab = build_vocab_from_iterator(yield_tokens(train_data['english']), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
    "\n",
    "hindi_vocab.set_default_index(hindi_vocab[\"<unk>\"])\n",
    "english_vocab.set_default_index(english_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2414c",
   "metadata": {},
   "source": [
    "Numericalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eac2c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(sentence, vocab):\n",
    "    tokens = sentence.split()\n",
    "    return [vocab[\"<sos>\"]] + [vocab.get(token, vocab[\"<unk>\"]) for token in tokens] + [vocab[\"<eos>\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb739aa8",
   "metadata": {},
   "source": [
    "Custom Dataset for English → Hindi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, src_vocab, tgt_vocab):\n",
    "        self.source = source_sentences  # English\n",
    "        self.target = target_sentences  # Hindi\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = str(self.source[idx])\n",
    "        tgt_sentence = str(self.target[idx])\n",
    "    \n",
    "        src = numericalize(src_sentence, self.src_vocab)\n",
    "        tgt = numericalize(tgt_sentence, self.tgt_vocab)\n",
    "    \n",
    "        return torch.tensor(src), torch.tensor(tgt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a1e42",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4fb68ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=english_vocab[\"<pad>\"])\n",
    "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=hindi_vocab[\"<pad>\"])\n",
    "\n",
    "    return src_batch, tgt_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc8f33",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "415dbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = TranslationDataset(\n",
    "    source_sentences=train_data['english'],\n",
    "    target_sentences=train_data['hindi'],\n",
    "    src_vocab=english_vocab,\n",
    "    tgt_vocab=hindi_vocab\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9b08abd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x141380cf430>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ee89c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9f776",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "50600613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [batch_size, src_len]\n",
    "        embedded = self.dropout(self.embedding(src))  # [batch_size, src_len, emb_dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)  # hidden/cell: [num_layers, batch_size, hidden_dim]\n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705c40e",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3f6d7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c898dc",
   "metadata": {},
   "source": [
    "Define Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fe67bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b31bf2",
   "metadata": {},
   "source": [
    "Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c59b7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(hindi_vocab)\n",
    "OUTPUT_DIM = len(english_vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0f0e6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615bb61",
   "metadata": {},
   "source": [
    "Initialize model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ddb265cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HIDDEN_DIM, NUM_LAYERS, ENC_DROPOUT)\n",
    "decoder = Encoder(OUTPUT_DIM,DEC_EMB_DIM,HIDDEN_DIM,NUM_LAYERS,DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder,decoder,device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee41c7",
   "metadata": {},
   "source": [
    "Define Loss Funtion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e2d7dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "PAD_IDX = english_vocab['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1921261",
   "metadata": {},
   "source": [
    "Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d940fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, trg in dataloader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)  # output: [batch_size, trg_len, output_dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # reshape for loss: flatten trg and output\n",
    "        output = output[:, 1:].reshape(-1, output_dim)  # skip <sos>\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043af13",
   "metadata": {},
   "source": [
    "Define evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "26f5ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902207d",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6683a525",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Vocab' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m CLIP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m----> 5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, train_loader, criterion)  \u001b[38;5;66;03m# using train_loader as placeholder\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[192], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, trg \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      6\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m     trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Rajnish Kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Rajnish Kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Rajnish Kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Rajnish Kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[180], line 15\u001b[0m, in \u001b[0;36mTranslationDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 15\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mnumericalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_vocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m numericalize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_vocab)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(src), torch\u001b[38;5;241m.\u001b[39mtensor(tgt)\n",
      "Cell \u001b[1;32mIn[179], line 3\u001b[0m, in \u001b[0;36mnumericalize\u001b[1;34m(sentence, vocab)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnumericalize\u001b[39m(sentence, vocab):\n\u001b[0;32m      2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<sos>\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m [vocab\u001b[38;5;241m.\u001b[39mget(token, vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;241m+\u001b[39m [vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[179], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnumericalize\u001b[39m(sentence, vocab):\n\u001b[0;32m      2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<sos>\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m [\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(token, vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;241m+\u001b[39m [vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\Rajnish Kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Vocab' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    val_loss = evaluate(model, train_loader, criterion)  # using train_loader as placeholder\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
    "    print(f\"\\t Val. Loss: {val_loss:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
