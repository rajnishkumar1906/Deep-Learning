{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZozl/WYHCZQyNEjCCi6Lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajnishkumar1906/Deep-Learning/blob/main/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall preinstalled versions\n",
        "!pip uninstall -y torch torchvision torchaudio torchtext\n",
        "\n",
        "# Install compatible versions (example for torch 2.1.2)\n",
        "# Allow pip to choose a compatible torchtext version\n",
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAC9WHing9yK",
        "outputId": "5fb6cf9b-68cf-4207-d759-0fc106e01e67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.1.2\n",
            "Uninstalling torch-2.1.2:\n",
            "  Successfully uninstalled torch-2.1.2\n",
            "Found existing installation: torchvision 0.16.2\n",
            "Uninstalling torchvision-0.16.2:\n",
            "  Successfully uninstalled torchvision-0.16.2\n",
            "Found existing installation: torchaudio 2.1.2\n",
            "Uninstalling torchaudio-2.1.2:\n",
            "  Successfully uninstalled torchaudio-2.1.2\n",
            "Found existing installation: torchtext 0.16.2\n",
            "Uninstalling torchtext-0.16.2:\n",
            "  Successfully uninstalled torchtext-0.16.2\n",
            "Collecting torch==2.1.2\n",
            "  Using cached torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.16.2\n",
            "  Using cached torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.1.2\n",
            "  Using cached torchaudio-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.4.127)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "  Using cached torchtext-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "  Using cached torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "  Using cached torchtext-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Using cached torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "Using cached torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
            "Using cached torchaudio-2.1.2-cp311-cp311-manylinux1_x86_64.whl (3.3 MB)\n",
            "Using cached torchtext-0.16.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "Installing collected packages: torch, torchvision, torchaudio, torchtext\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.2 torchaudio-2.1.2 torchtext-0.16.2 torchvision-0.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This project performs sentiment analysis on IMDB movie reviews using a Feedforward Neural Network (FFNN). The goal is to classify each review as positive or negative based on its text content.\n",
        "\n",
        ">Tokenize and vectorize the text using a fixed-size vocabulary.\n",
        "\n",
        ">Convert reviews into binary vectors (indicating presence of words).\n",
        "\n",
        ">Train a simple FFNN with one hidden layer.\n",
        "\n",
        ">Evaluate model performance on a test set.\n",
        "\n",
        ">Use the trained model to predict sentiment on new reviews.\n",
        "\n",
        ">This project introduces basic deep learning concepts for NLP, using FFNN     instead of more complex models like RNNs or LSTMs."
      ],
      "metadata": {
        "id": "fvi7U1He5Z-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "xpNPG8xWvRQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CTKex3YhBMT",
        "outputId": "dfe992a3-0821-43d5-973f-f3da8545fd3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load IMDB dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DATASETS/IMDB Dataset.csv\")\n",
        "\n",
        "# Convert sentiment labels to binary (positive:1, negative:0)\n",
        "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "df = df[['review', 'label']]"
      ],
      "metadata": {
        "id": "6p7OK090qK-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rvw = df['review'][0]\n",
        "len(rvw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4p0qyTxzxs",
        "outputId": "101d6d48-1d51-48d7-d7e0-f320c13b2eb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1761"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize and vocabulary"
      ],
      "metadata": {
        "id": "VpiG94sVsDNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Build vocabulary from most common tokens\n",
        "VOCAB_SIZE = 5000\n",
        "specials = ['<PAD>', '<UNK>']\n",
        "counter = Counter()\n",
        "\n",
        "for review in df['review']:\n",
        "    counter.update(tokenizer(review))\n",
        "\n",
        "# Assign indices to words\n",
        "vocab = {word: idx + len(specials) for idx, (word, _) in enumerate(counter.most_common(VOCAB_SIZE - len(specials)))}\n",
        "vocab['<PAD>'] = 0\n",
        "vocab['<UNK>'] = 1\n"
      ],
      "metadata": {
        "id": "KtGRRQ3wqmWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad41bce-8dd4-418c-dd9a-1a9f127fd29e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-5-3209790620.py\", line 1, in <cell line: 0>\n",
            "    from torchtext.data.utils import get_tokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtext/__init__.py\", line 3, in <module>\n",
            "    from torch.hub import _get_torch_home\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Reviews as Sequences of Token IDs\n",
        "\n"
      ],
      "metadata": {
        "id": "jUfyP0uetaXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "MAX_LEN = 200\n",
        "\n",
        "def encode_review(text):\n",
        "    tokens = tokenizer(text)\n",
        "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
        "\n",
        "encoded = [torch.tensor(encode_review(review), dtype=torch.long) for review in df['review']]\n",
        "\n",
        "padded = pad_sequence(\n",
        "    [r[:MAX_LEN] if len(r) > MAX_LEN else torch.cat([r, torch.zeros(MAX_LEN - len(r), dtype=torch.long)])\n",
        "     for r in encoded],\n",
        "    batch_first=True\n",
        ")\n",
        "\n",
        "X = padded\n",
        "y = torch.tensor(df['label'].values, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "i1RmK4eAsKAY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split"
      ],
      "metadata": {
        "id": "UQuUfOUPtg3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]"
      ],
      "metadata": {
        "id": "OUqksT2DteV9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "nTFW2RSRt4Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64)"
      ],
      "metadata": {
        "id": "fTxsKYketj4E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "MzhcSXvdt-sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)        # (batch, seq_len, embed_dim)\n",
        "        x = x.mean(dim=1)            # average pooling over sequence\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "bQBvgO0guA4V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize model"
      ],
      "metadata": {
        "id": "Si3hP1VXuHte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SimpleTextClassifier(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "Of7Cf31juCSP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "O5QSb89TuXLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 5\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0XcBujuKd4",
        "outputId": "273fc97d-6433-4c85-b593-b469dc4731b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 314.4650\n",
            "Epoch 2/5 - Loss: 214.1900\n",
            "Epoch 3/5 - Loss: 186.8197\n",
            "Epoch 4/5 - Loss: 172.1896\n",
            "Epoch 5/5 - Loss: 162.8905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate accuracy"
      ],
      "metadata": {
        "id": "NI4kyhtnu1lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq3WFWgmuaYM",
        "outputId": "5feab548-03ee-4144-df39-b4c0c1cdc4f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 86.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "380_-n-Gu9H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    model.eval()\n",
        "    tokens = encode_review(text)\n",
        "    if len(tokens) < MAX_LEN:\n",
        "        tokens += [0] * (MAX_LEN - len(tokens))\n",
        "    else:\n",
        "        tokens = tokens[:MAX_LEN]\n",
        "    input_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred = torch.argmax(output, dim=1).item()\n",
        "    return \"positive\" if pred == 1 else \"negative\"\n",
        "\n",
        "print(predict(\"This movie was absolutely amazing!\"))\n",
        "print(predict(\"Worst plot ever. Waste of time.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzHL1KHNu4ct",
        "outputId": "65c8a9d1-fdce-4242-cb78-c10c73988a47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n",
            "negative\n"
          ]
        }
      ]
    }
  ]
}